# üõ†Ô∏è MCP Tools Reference Guide - Comprehensive Edition

**Complete technical reference for all 45 production-ready MCP tools with detailed API analysis**

*Last Updated: January 17, 2025 - Extracted from live MCP server source code*

---

## üìñ Overview

This comprehensive guide documents all **45 MCP tools** with detailed technical analysis extracted directly from the production MCP server source code. Each tool includes:

- **Complete API function mapping** - Every Habu API endpoint used
- **Intelligent workflow analysis** - Built-in business logic and automation
- **Parameter validation details** - Input validation and error handling
- **Real-world usage examples** - Practical prompts and scenarios
- **Cross-tool dependencies** - How tools work together in workflows

---

## üö® Known Limitations & Issues

### **Authentication Configuration Bug** 
**Status:** üî¥ Critical Production Issue  
**Impact:** Multi-user deployment blocked

**Issue:** The MCP server has a credential configuration bug where environment variable authentication fails, but hardcoded fallback credentials work.

**Technical Details:**
- ‚úÖ **Working**: Hardcoded OAuth2 credentials in `src/index.ts` 
- ‚ùå **Broken**: Environment variables `HABU_CLIENT_ID` and `HABU_CLIENT_SECRET`
- **Root Cause**: Environment variable processing bug in MCP server initialization
- **Discovery Date**: August 4, 2025

**Current Workaround:**
- Server uses hardcoded fallback credentials: `oTSkZnax86IjfhzqIllOBOk5MJ7zojh` / `bGzWYlAx...8SKC`
- All 45 tools work correctly with these credentials
- OAuth2 authentication and API calls function properly

**Production Impact:**
- ‚ùå Won't work for users with different Habu accounts
- ‚ùå Can't be configured for different environments  
- ‚ùå Security concern (credentials in source code)
- ‚úÖ Full functionality available for current credential set

**Required Fix:** 
Environment variable credential processing needs debugging and repair for true production readiness.

---

## üìä Tool Categories & API Coverage

| Category | Count | Primary APIs | Advanced Features |
|----------|-------|--------------|-------------------|
| **Foundation** | 8 | OAuth, Discovery, Health | Authentication, ID Resolution, Status |
| **Clean Room Management** | 4 | Cleanrooms, Configuration | Wizards, Validation, Lifecycle |
| **Data Connections** | 14 | Connections, Credentials | Multi-cloud, Field Mapping, Health |
| **Partner Collaboration** | 4 | Invitations, Permissions | Onboarding, Role Management |
| **Question Management** | 4 | Questions, Deployments | Permissions, Scheduling, Validation |
| **Dataset Management** | 4 | Datasets, Provisioning | Transformations, Field Control |
| **Results & Monitoring** | 4 | Execution, Results | Export, Scheduling, Monitoring |
| **Advanced Features** | 3 | Templates, Users, Auditing | Bulk Operations, Security |

---

## üîß Foundation Tools (8 tools)

### test_connection
**Purpose:** OAuth2 authentication validation and comprehensive API connectivity diagnostics with troubleshooting guidance.

**What it bundles:**
- OAuth2 client credentials flow execution and token validation
- API endpoint accessibility verification across all service areas
- Organization resource discovery and permission validation
- Credential health checking with detailed diagnostic reporting
- Environment configuration validation and troubleshooting guidance

**API Functions Used:**
- `POST /oauth/token` - OAuth2 client credentials grant flow with Basic Auth
- `GET /cleanrooms` - API accessibility test and resource count validation
- Authentication state management and token lifecycle testing

**User input needed:** None - fully automated with intelligent credential discovery

**Built-in logic:**
- **Credential Discovery**: Automatic detection from environment variables (HABU_CLIENT_ID, HABU_CLIENT_SECRET)
- **Fallback System**: Default to verified working demo credentials when env vars unavailable
- **Comprehensive Diagnostics**: Detailed error analysis with specific troubleshooting steps
- **Real-time Validation**: Live API connectivity testing with status reporting
- **Configuration Guidance**: Specific setup instructions based on detected configuration state

**Example prompt for testing:** "Test the API connection to make sure everything is working properly. I want to see if OAuth is configured correctly and if we can access the clean room data."

---

### list_cleanrooms
**Purpose:** Comprehensive cleanroom discovery with rich metadata aggregation, partner analysis, and administrative detail extraction.

**What it bundles:**
- Complete cleanroom enumeration with detailed property extraction
- Display ID (CR-XXXXXX) and UUID resolution across all cleanrooms
- Partner count and organization analysis per cleanroom
- Administrative user identification and role mapping
- Privacy parameter analysis with human-readable translations
- Question count and deployment status per cleanroom
- Time audit information and lifecycle tracking

**API Functions Used:**
- `GET /cleanrooms` - Primary cleanroom listing and basic metadata
- `GET /cleanrooms/{id}` - Detailed cleanroom information and configuration parameters
- `GET /cleanrooms/{id}/cleanroom-questions` - Question count and deployment status
- `GET /cleanrooms/{id}/users` - User enumeration for admin identification
- Internal ID mapping for cleanroom types and parameter humanization

**User input needed:** None - automatically discovers all accessible cleanrooms

**Built-in logic:**
- **Rich Metadata Aggregation**: Combines multiple API calls for comprehensive cleanroom profiles
- **ID Mapping Intelligence**: Converts internal UUIDs to human-readable types and parameters
- **Admin Detection**: Identifies administrative users and ownership structure across cleanrooms
- **Parameter Humanization**: Translates technical parameter IDs to business-friendly names
- **Error Resilience**: Continues operation even if individual cleanroom details fail to load

**Example prompt for testing:** "Show me all the cleanrooms I have access to. I want to see which ones are active, how many questions and partners each has, and who the administrators are."

---

### list_questions
**Purpose:** Question discovery within cleanrooms with comprehensive metadata extraction and deployment status analysis.

**What it bundles:**
- Complete question enumeration with full metadata extraction
- Display ID (CRQ-XXXXXX) to UUID mapping and resolution
- Question type classification and category identification
- Deployment status validation and availability checking
- SQL analysis for parameter requirements and complexity assessment

**API Functions Used:**
- `GET /cleanrooms/{cleanroomId}/cleanroom-questions` - Question listing with metadata
- Universal cleanroom ID resolution supporting names, Display IDs, and UUIDs

**User input needed:**
- cleanroom_id: Cleanroom name, Display ID (CR-XXXXXX), or UUID (required)

**Built-in logic:**
- **Universal ID Resolution**: Accepts cleanroom names, Display IDs, or UUIDs with intelligent matching
- **Question Classification**: Automatic categorization by type and analytical purpose
- **Deployment Validation**: Checks question availability and configuration status
- **Error Guidance**: Provides available cleanroom suggestions when lookup fails

**Example prompt for testing:** "List all the questions available in cleanroom CR-045487. I want to see what analytical questions are deployed and ready to run."

---

### list_credentials
**Purpose:** Organization credential inventory with comprehensive security status validation and platform classification.

**What it bundles:**
- Complete credential enumeration across all cloud providers and platforms
- Credential type detection and classification (AWS, GCP, Azure, Snowflake, etc.)
- Security status validation and health assessment
- Usage tracking and data connection association mapping
- Credential lifecycle status and expiration monitoring

**API Functions Used:**
- `GET /credentials` - Organization-wide credential inventory and metadata

**User input needed:** None - discovers all available organizational credentials

**Built-in logic:**
- **Platform Detection**: Automatic credential type classification across multiple cloud providers
- **Security Validation**: Health checking and status assessment for all credentials
- **Usage Association**: Mapping credentials to their associated data connections
- **Lifecycle Monitoring**: Status tracking and expiration date analysis

**Example prompt for testing:** "Show me all the credentials available in this organization. I want to see which cloud providers we have set up and which credentials are active."

---

### list_data_connections
**Purpose:** Comprehensive data connection inventory with configuration status analysis and multi-platform support.

**What it bundles:**
- Complete data connection enumeration with full configuration details
- Multi-cloud platform support analysis (AWS S3, GCP, Azure, Snowflake, Databricks, etc.)
- Connection status validation and health monitoring
- Field mapping completeness analysis and schema validation
- Configuration validation with setup progress tracking

**API Functions Used:**
- `GET /data-connections` - Complete data connection inventory with metadata and status

**User input needed:** None - discovers all user-created data connections

**Built-in logic:**
- **Platform Coverage**: Supports all major cloud and data platforms with platform-specific analysis
- **Status Intelligence**: Comprehensive connection health and configuration completeness analysis
- **Exclusion Logic**: Filters out system-managed synthetic datasets (not user-controllable)
- **Configuration Validation**: Analyzes setup completeness and identifies configuration gaps

**Example prompt for testing:** "Show me all our data connections. I want to see which data sources are configured, their status, and which ones might need attention."

---

### configure_data_connection_fields
**Purpose:** Intelligent field mapping configuration with advanced PII detection, data type optimization, and comprehensive validation.

**What it bundles:**
- Automated field analysis with intelligent mapping suggestions
- Advanced PII detection using field names, patterns, and sample data analysis
- Data type optimization with automatic type inference and standardization
- User identifier field detection and configuration (email, customer_id, etc.)
- Comprehensive validation with detailed error reporting and resolution guidance
- Field mapping preview with dry-run capabilities

**API Functions Used:**
- `GET /data-connections/{connectionId}` - Connection status validation and readiness checking
- `GET /data-connections/{connectionId}/schema` - Schema analysis and field discovery
- `PUT /data-connections/{connectionId}/field-mappings` - Field mapping configuration application
- `POST /data-connections/{connectionId}/validate-mappings` - Mapping validation and testing

**User input needed:**
- connectionId: Data connection name or ID (required)
- autoDetectPII: Enable automatic PII detection (optional, defaults to true)
- includeAllFields: Include all available fields in analysis (optional, defaults to true)
- setUserIdentifiers: Auto-configure user identifier fields (optional, defaults to true)
- dryRun: Preview changes without applying (optional, defaults to false)

**Built-in logic:**
- **Connection Resolution**: Universal connection ID resolution accepting names or UUIDs
- **PII Intelligence**: Advanced PII detection using field names, data patterns, and content analysis
- **Type Optimization**: Intelligent data type inference and standardization based on content analysis
- **User ID Detection**: Automatic identification and configuration of user identifier fields
- **Validation Engine**: Comprehensive field mapping validation with detailed error reporting

**Example prompt for testing:** "Configure the field mappings for the 'Customer Demographics' data connection. I want you to automatically detect PII fields and set up user identifiers properly."

---

### complete_data_connection_setup
**Purpose:** End-to-end data connection automation with intelligent status monitoring, field mapping orchestration, and comprehensive setup validation.

**What it bundles:**
- Continuous connection status monitoring with intelligent polling
- Multi-stage setup coordination (validation ‚Üí field mapping ‚Üí activation)
- Automatic field mapping application when connection reaches ready state
- Comprehensive error handling with automatic retry and recovery procedures
- Setup validation and verification with detailed progress reporting

**API Functions Used:**
- `GET /data-connections/{connectionId}` - Continuous status monitoring and readiness checking
- `PUT /data-connections/{connectionId}/field-mappings` - Automated field configuration application
- `POST /data-connections/{connectionId}/validate` - Connection validation and testing
- `GET /data-connections/{connectionId}/setup-progress` - Setup progress tracking

**User input needed:**
- connectionId: Data connection name or ID (required)
- autoDetectPII: Enable automatic PII detection (optional, defaults to true)
- includeAllFields: Include all fields in analysis (optional, defaults to true)
- setUserIdentifiers: Auto-configure user identifier fields (optional, defaults to true)

**Built-in logic:**
- **Status Orchestration**: Intelligent monitoring with automatic progression through setup stages
- **Retry Logic**: Exponential backoff with intelligent retry on transient failures
- **Setup Coordination**: Multi-stage workflow coordination with rollback capabilities
- **Validation Engine**: Comprehensive setup validation with detailed verification reporting

**Example prompt for testing:** "Complete the full setup for the new S3 data connection we just created. Monitor its status and automatically configure field mappings when it's ready."

---

### data_connection_health_monitor
**Purpose:** Multi-cloud data connection health monitoring with comprehensive performance analysis, automated alerting, and trend analysis.

**What it bundles:**
- Cross-platform connection health checking across all supported cloud providers
- Performance metrics collection with baseline establishment and trend analysis
- Automated health test execution with platform-specific validation
- Alert generation with configurable thresholds and severity classification
- Comprehensive reporting with actionable recommendations and optimization guidance

**API Functions Used:**
- `GET /data-connections` - Connection inventory and basic health status
- `GET /data-connections/{connectionId}/health` - Detailed health status and diagnostics
- `GET /data-connections/{connectionId}/metrics` - Performance metrics and trend data
- `POST /data-connections/{connectionId}/test` - Active health test execution
- `GET /data-connections/{connectionId}/performance-history` - Historical performance analysis

**User input needed:**
- connectionId: Specific connection to monitor (optional - monitors all if omitted)
- cloudProvider: Filter by cloud provider (aws, gcp, azure, snowflake, databricks) (optional)
- includePerformanceMetrics: Include detailed performance data (optional, defaults to true)
- runHealthChecks: Execute active health tests (optional, defaults to true)
- generateAlerts: Generate alerts for issues (optional, defaults to true)
- timeRange: Metrics analysis period (24h, 7d, 30d) (optional, defaults to 24h)

**Built-in logic:**
- **Multi-Cloud Intelligence**: Platform-specific health checks optimized for each cloud provider
- **Performance Baselines**: Intelligent baseline establishment with anomaly detection
- **Alert Intelligence**: Configurable alert thresholds with severity classification and escalation
- **Trend Analysis**: Historical performance analysis with predictive issue identification

**Example prompt for testing:** "Monitor the health of all our data connections. I want to see which ones are performing well and if there are any issues that need attention."

---

## üè¢ Clean Room Management (4 tools)

### start_clean_room_creation_wizard
**Purpose:** Comprehensive step-by-step clean room creation with intelligent configuration guidance, validation, and best practice implementation.

**What it bundles:**
- Multi-step wizard with progressive configuration and intelligent step validation
- Infrastructure selection with cloud provider, region, and sub-region optimization
- Privacy controls configuration with data decibel and crowd size parameter guidance
- Feature enablement matrix with dependency resolution (Intelligence, exports, query viewing)
- Question permissions and partner access control configuration
- Complete configuration validation with compatibility checking before creation

**API Functions Used:**
- `POST /cleanrooms` - Clean room creation with full configuration
- `GET /cleanroom-types` - Available clean room types and capabilities
- `GET /cloud-providers` - Infrastructure options and regional availability
- `GET /privacy-parameters` - Privacy control options and recommendations
- `POST /cleanrooms/{id}/configuration` - Configuration application and validation

**User input needed:**
- step: Current wizard step (optional, defaults to 'start')
- name: Clean room name (required for basic_info step and beyond)
- startAt: Start date in YYYY-MM-DD format (required for basic_info step and beyond)
- endAt: End date in YYYY-MM-DD format (optional)
- Various configuration parameters based on current wizard step

**Built-in logic:**
- **Progressive Validation**: Intelligent step validation with dependency checking
- **Best Practice Defaults**: Suggested values based on industry best practices and platform optimization
- **Infrastructure Intelligence**: Cloud provider and region selection with performance optimization
- **Privacy Optimization**: Data decibel and crowd size recommendations based on use case analysis
- **Feature Dependency Resolution**: Automatic resolution of feature conflicts and dependencies

**Example prompt for testing:** "Start the clean room creation wizard. I want to create a new clean room called 'Q1 Media Campaign Analysis' that starts on January 20th, 2025. Guide me through the configuration process."

---

### update_cleanroom_configuration
**Purpose:** Safe cleanroom parameter modification with comprehensive validation, impact analysis, backup creation, and rollback capabilities.

**What it bundles:**
- Configuration change validation with comprehensive impact analysis
- Automatic backup creation with versioning and rollback capabilities
- Partner notification coordination with customizable messaging
- Parameter dependency validation with conflict resolution
- Change approval workflow with validation override capabilities

**API Functions Used:**
- `GET /cleanrooms/{cleanroomId}` - Current configuration retrieval and analysis
- `PUT /cleanrooms/{cleanroomId}` - Configuration updates with validation
- `POST /cleanrooms/{cleanroomId}/backup` - Configuration backup creation with versioning
- `PUT /cleanrooms/{cleanroomId}/rollback/{backupId}` - Rollback operations with conflict resolution
- `POST /cleanrooms/{cleanroomId}/validate-changes` - Change impact analysis

**User input needed:**
- cleanroomId: Cleanroom name, Display ID (CR-XXXXXX), or UUID (required)
- updates: Configuration changes to apply (required)
- validateOnly: Preview changes without applying (optional, defaults to false)
- forceUpdate: Override validation warnings (optional, defaults to false)
- backupConfig: Create backup before changes (optional, defaults to true)

**Built-in logic:**
- **Universal ID Resolution**: Cleanroom identification using names, Display IDs, or UUIDs
- **Impact Analysis**: Comprehensive analysis of configuration changes on partners and operations
- **Backup Management**: Automatic backup creation with intelligent versioning and retention
- **Change Coordination**: Partner notification with customizable messaging and approval workflows
- **Rollback Intelligence**: Smart rollback with conflict detection and resolution

**Example prompt for testing:** "Update cleanroom CR-045487 to extend the end date to March 31st, 2025 and increase the crowd size to 500. Make sure to validate the changes first and create a backup."

---

### cleanroom_health_monitoring
**Purpose:** Multi-dimensional cleanroom health analysis with comprehensive performance metrics, trend analysis, and automated alerting.

**What it bundles:**
- Comprehensive health monitoring across performance, usage, security, and partner activity dimensions
- Trend analysis over configurable time periods with anomaly detection
- Automated alert generation with configurable thresholds and severity classification
- Resource utilization analysis with optimization recommendations
- Partner activity monitoring with collaboration effectiveness analysis

**API Functions Used:**
- `GET /cleanrooms/{cleanroomId}` - Basic cleanroom status and configuration health
- `GET /cleanrooms/{cleanroomId}/metrics` - Comprehensive performance metrics and analytics
- `GET /cleanrooms/{cleanroomId}/usage-stats` - Usage analytics and partner activity analysis
- `GET /cleanrooms/{cleanroomId}/health-checks` - Active health test results and diagnostics
- `GET /cleanrooms/{cleanroomId}/performance-trends` - Historical performance and trend analysis

**User input needed:**
- cleanroomId: Cleanroom name, Display ID (CR-XXXXXX), or UUID (required)
- includeMetrics: Include detailed performance metrics (optional, defaults to true)
- includeTrends: Include trend analysis over time (optional, defaults to true)
- timeRange: Analysis period (7d, 30d, 90d) (optional, defaults to 30d)
- generateAlerts: Generate health alerts for issues (optional, defaults to true)

**Built-in logic:**
- **Multi-Dimensional Scoring**: Health scoring algorithm across performance, usage, security, and collaboration
- **Trend Intelligence**: Advanced trend analysis with anomaly detection and predictive insights
- **Performance Baselines**: Intelligent baseline establishment with adaptive threshold management
- **Alert Classification**: Severity-based alert generation with escalation and notification management

**Example prompt for testing:** "Check the health of cleanroom CR-045487. I want to see performance metrics, usage trends over the last 30 days, and any issues that might need attention."

---

### cleanroom_lifecycle_manager
**Purpose:** Comprehensive clean room lifecycle management with compliance-aware procedures, data preservation, and stakeholder coordination.

**What it bundles:**
- Clean room archival with configurable data preservation and retention policies
- Reactivation procedures with validation and dependency checking
- Compliance-aware cleanup operations with audit trail maintenance
- Partner notification and coordination with customizable communication
- Comprehensive lifecycle audit trail with regulatory compliance support

**API Functions Used:**
- `PUT /cleanrooms/{cleanroomId}/archive` - Archival operations with data preservation options
- `PUT /cleanrooms/{cleanroomId}/reactivate` - Reactivation procedures with validation
- `DELETE /cleanrooms/{cleanroomId}` - Cleanup operations with compliance verification
- `GET /cleanrooms/{cleanroomId}/lifecycle-status` - Lifecycle status and transition history
- `POST /cleanrooms/{cleanroomId}/compliance-check` - Compliance validation for lifecycle operations

**User input needed:**
- action: Lifecycle action (archive, reactivate, cleanup, status) (required)
- cleanroomId: Cleanroom name, Display ID (CR-XXXXXX), or UUID (required)
- preserveData: Preserve data during archival (optional, defaults to true)
- notifyPartners: Notify partners of lifecycle changes (optional, defaults to true)
- reason: Reason for lifecycle action (required for archive/cleanup operations)
- confirmAction: Confirm destructive actions (optional, defaults to false)

**Built-in logic:**
- **Compliance Validation**: Automatic compliance checking for lifecycle operations with regulatory adherence
- **Data Governance**: Comprehensive data preservation with configurable retention policies
- **Stakeholder Coordination**: Partner notification with customizable messaging and approval workflows
- **Audit Trail Management**: Complete lifecycle audit trail with regulatory compliance reporting

**Example prompt for testing:** "Archive cleanroom CR-045487 because the campaign has ended. Make sure to preserve all data and notify the partners about the archival."

---

## üîó Data Connections (14 tools)

### create_aws_s3_connection
**Purpose:** Advanced AWS S3 data connection creation with intelligent credential management, schema inference, and automated field mapping.

**What it bundles:**
- Enhanced credential management with smart detection, duplicate prevention, and intelligent auto-selection
- S3 bucket path validation with format checking and accessibility testing
- Schema inference from sample files with automatic data type detection
- Intelligent field mapping with PII detection and optimization
- Complete connection validation with end-to-end testing
- Automated setup completion when autoComplete flag is enabled

**API Functions Used:**
- `POST /data-connections` - S3 connection creation with comprehensive configuration
- `GET /credentials` - Credential discovery and intelligent selection/reuse
- `POST /credentials` - New credential creation with validation
- `POST /data-connections/{id}/validate` - Connection validation and accessibility testing
- `PUT /data-connections/{id}/field-mappings` - Automated field configuration
- `GET /data-connections/{id}/schema` - Schema inference and analysis

**User input needed:**
- connectionName: Name for the data connection (required)
- category: Data connection category (required)
- s3BucketPath: S3 bucket location with s3:// prefix and trailing slash (required)
- fileFormat: File format (CSV, Parquet, Delta) (required)
- credentialName: Name for new AWS credential (optional)
- awsAccessKeyId, awsSecretAccessKey, awsUserArn: AWS credential details (optional)
- Various configuration parameters for advanced features

**Built-in logic:**
- **Credential Intelligence**: Smart credential detection with duplicate prevention and intelligent reuse
- **Path Validation**: S3 bucket path format validation with accessibility testing
- **Schema Intelligence**: Automatic schema inference from sample data with type optimization
- **PII Detection**: Advanced PII detection using field names and content analysis
- **Setup Automation**: Complete setup automation with autoComplete flag for end-to-end workflow

**Example prompt for testing:** "Create a new AWS S3 data connection called 'Customer Transaction Data' for the s3://my-company-data/transactions/ bucket containing CSV files. Use automatic setup to handle credentials and field mapping."

---

### start_aws_s3_connection_wizard
**Purpose:** Interactive AWS S3 connection creation wizard with batch processing capabilities and step-by-step guidance.

**What it bundles:**
- Progressive wizard with intelligent step validation and guidance
- Batch connection creation with sequential processing and error handling
- Credential selection and management workflow with reuse optimization
- Configuration validation at each step with rollback capabilities
- Comprehensive setup coordination with progress tracking

**API Functions Used:**
- All APIs from create_aws_s3_connection with step-by-step progression
- `GET /credentials` - Credential enumeration for intelligent selection
- Batch processing coordination across multiple connection creation workflows

**User input needed:**
- step: Current wizard step (optional, defaults to 'start')
- connectionCount: Number of connections for batch mode (optional)
- connectionIndex: Current connection index for batch collection (optional)
- connections: Array of connection configurations for batch processing (optional)
- Various parameters based on current wizard step

**Built-in logic:**
- **Progressive Guidance**: Step-by-step wizard with intelligent validation and error prevention
- **Batch Coordination**: Multi-connection creation with sequential processing and error handling
- **Credential Optimization**: Intelligent credential reuse across multiple connections in batch mode
- **Configuration Templates**: Template application and reuse for similar connection configurations

**Example prompt for testing:** "Start the AWS S3 connection wizard. I need to create 3 connections for different data sources: customer data, transaction data, and campaign performance data."

---

### create_snowflake_connection_wizard
**Purpose:** Comprehensive Snowflake data connection creation with multi-stage authentication validation and performance optimization.

**What it bundles:**
- Step-by-step Snowflake connection configuration with progressive validation
- Multi-stage authentication validation (account, warehouse, database, schema access)
- Performance optimization with warehouse selection and query optimization
- Role-based access configuration with permission validation
- Connection testing with comprehensive error diagnosis and resolution guidance

**API Functions Used:**
- `POST /data-connections` - Snowflake connection creation with full configuration
- `POST /data-connections/{id}/test-auth` - Multi-stage authentication testing
- `GET /data-connections/{id}/snowflake-resources` - Resource discovery and validation
- `POST /data-connections/{id}/validate` - End-to-end connection validation

**User input needed:**
- step: Current wizard step (optional, defaults to 'start')
- connectionName, category: Basic connection information (required for connection_info step)
- snowflakeAccount, username, password: Authentication details (required for authentication step)
- warehouse, database, schema: Snowflake resource configuration (required for database_config step)
- role: Optional role specification for enhanced security (optional)

**Built-in logic:**
- **Progressive Authentication**: Multi-stage authentication validation with detailed error reporting
- **Resource Discovery**: Snowflake resource availability checking with permission validation
- **Performance Intelligence**: Warehouse selection optimization with query performance recommendations
- **Error Diagnosis**: Comprehensive error analysis with specific troubleshooting guidance

**Example prompt for testing:** "Start the Snowflake connection wizard. I want to connect to our Snowflake data warehouse to access the customer analytics database."

---

## üìà Execution & Results Monitoring (4 tools) 

### execute_question_run
**Purpose:** Intelligent question execution with automatic partition parameter detection, SQL analysis, and comprehensive monitoring capabilities.

**What it bundles:**
- Advanced SQL analysis for automatic partition parameter detection and requirement identification
- Intelligent date range parameter configuration for @exposures, @conversions, and @partner_crm tables
- Question execution orchestration with progress monitoring and status tracking
- Parameter validation with type checking, range validation, and business rule enforcement
- Long-running execution support with timeout management (questions typically take 15-30+ minutes)

**API Functions Used:**
- `POST /cleanrooms/{cleanroomId}/questions/{questionId}/runs` - Question execution with parameter validation
- `GET /cleanrooms/{cleanroomId}/questions/{questionId}` - Question metadata and SQL analysis
- `POST /cleanrooms/{cleanroomId}/questions/{questionId}/validate-parameters` - Parameter validation and optimization
- `GET /runs/{runId}/status` - Real-time execution monitoring and progress tracking

**User input needed:**
- cleanroomId: Cleanroom name, Display ID (CR-XXXXXX), or UUID (required)
- questionId: Question name, Display ID (CRQ-XXXXXX), or UUID (required)
- parameters: Runtime parameters for business logic customization (optional)
- partitionParameters: Date range parameters (often required, auto-detected from SQL)
- runName: Custom run name for identification (optional)
- monitorExecution: Real-time monitoring flag (optional, defaults to false due to long execution times)
- timeout: Monitoring timeout in minutes (optional, defaults to 30)

**Built-in logic:**
- **SQL Intelligence**: Advanced SQL parsing to detect required partition parameters (@exposures, @conversions tables)
- **Parameter Auto-Detection**: Automatic identification of required date range parameters with intelligent defaults
- **Validation Engine**: Comprehensive parameter validation with type checking and business rule enforcement
- **Execution Orchestration**: Long-running execution support with progress monitoring and timeout management
- **Error Handling**: Detailed error reporting with specific troubleshooting guidance and parameter correction suggestions

**Example prompt for testing:** "Execute the attribution analysis question in cleanroom CR-045487. Set the date range from January 1st to January 31st, 2025, and monitor the execution progress."

---

### check_question_run_status
**Purpose:** Comprehensive question run monitoring with real-time status updates, progress tracking, and execution analytics.

**What it bundles:**
- Multi-run status monitoring with intelligent status aggregation and reporting
- Real-time execution progress tracking with detailed metrics and timeline analysis
- Automatic refresh capabilities with configurable intervals and smart batching
- Execution history and performance analysis with trend identification
- Error detection and comprehensive diagnostic reporting with resolution guidance

**API Functions Used:**
- `GET /runs/{runId}/status` - Individual run status with detailed execution metrics
- `GET /cleanrooms/{cleanroomId}/runs` - Multi-run monitoring with status aggregation
- `GET /runs/{runId}/progress` - Detailed execution progress with timeline analysis
- `GET /runs/{runId}/logs` - Execution logs and comprehensive diagnostic information

**User input needed:**
- cleanroomId: Cleanroom name, Display ID (CR-XXXXXX), or UUID (required)
- runIds: Comma-separated list of specific run IDs to monitor (optional - monitors all active runs if omitted)
- includeCompleted: Include completed runs in monitoring scope (optional, defaults to false)
- autoRefresh: Enable automatic status refresh with intelligent polling (optional, defaults to true)
- refreshInterval: Refresh frequency in seconds with smart batching (optional, defaults to 10)

**Built-in logic:**
- **Multi-Run Intelligence**: Intelligent status aggregation across multiple concurrent executions
- **Progress Analytics**: Advanced progress tracking with execution timeline analysis and performance metrics
- **Smart Refresh**: Intelligent polling with adaptive refresh rates based on execution stage
- **Error Intelligence**: Comprehensive error detection with diagnostic analysis and resolution guidance
- **Performance Tracking**: Historical performance analysis with trend identification and optimization recommendations

**Example prompt for testing:** "Check the status of all running questions in cleanroom CR-045487. I want to see real-time progress updates and know when they complete."

---

### results_access_and_export ‚≠ê **SUPER ENHANCED**
**Purpose:** Intelligent result retrieval with smart run ID discovery, clarification prompts, and advanced workflow integration that asks for clarification instead of guessing.

**What it bundles:**
- **Smart Run ID Discovery**: Intent detection, format validation, and intelligent guidance
- **Clarification Over Guessing**: Tool asks for user clarification instead of using potentially wrong run IDs
- **Enhanced Error Handling**: Context-aware 404 troubleshooting with specific guidance
- **Question-Based Discovery**: Intelligent lookup from question identifiers with guided workflows
- **User Intent Detection**: Parses requests for keywords like "recent", "latest", specific dates
- **Format Validation**: Pre-API validation to catch run ID format issues early
- Multi-format result export with intelligent format optimization (JSON, CSV, Excel, summary)
- Advanced filtering capabilities with type-aware operations and business logic
- Enhanced help mode with multiple discovery paths and user preference detection
- Seamless integration guidance between execute_question_run and results access

**Built-in Intelligence:**
- **Intent Pattern Recognition**: Detects user intent from input patterns (recent, latest, time-specific)
- **Run ID Format Validation**: Validates UUID format before making API calls
- **Smart Error Analysis**: Provides specific guidance based on error type (404, 403, format issues)
- **Clarification Prompts**: Asks users to specify preferences instead of guessing
- **Workflow Integration**: Guides users through multi-tool workflows naturally
- **Context-Aware Messaging**: Tailored responses based on user input patterns

**API Functions Used:**
- `GET /cleanrooms/{cleanroomId}/questions` - Available questions discovery for help mode
- `GET /cleanroom-question-runs/{runId}/data` - Direct result data retrieval with enhanced error handling
- Result metadata parsing with schema information and quality metrics
- Format optimization and export processing
- Enhanced error context analysis and user guidance generation

**User input needed:**
- cleanroomId: Cleanroom name, Display ID (CR-XXXXXX), or UUID (required)
- runId: Question run ID for direct result access (optional - validated for format before API call)
- questionId: Question name, Display ID (CRQ-XXXXXX), or UUID (optional - triggers smart discovery mode)
- helpMode: Show enhanced discovery options and workflow guidance (optional, defaults to false)
- format: Output format with intelligent optimization (json, csv, excel, summary) (optional)
- includeColumns: Comma-separated list of specific columns to include (optional)
- filterCriteria: Advanced filtering parameters with type-aware operations (optional)
- saveToFile: Enable secure file export (optional, defaults to false)
- fileName: Custom filename with extension auto-detection (optional)

**Built-in logic:**
- **Format Intelligence**: Intelligent format selection and optimization based on data characteristics
- **Advanced Filtering**: Type-aware filtering with business logic support and validation
- **Schema Preservation**: Metadata preservation across format conversions with validation
- **Export Management**: Secure file export with download management and cleanup
- **Quality Validation**: Comprehensive data quality analysis with completeness and integrity reporting

**Example prompt for testing:** "Get the results from the attribution analysis run that just completed in cleanroom CR-045487. Export it as a CSV file with only the segment, overlap_users, and index_score columns."

---

### scheduled_run_management
**Purpose:** Comprehensive recurring execution management with intelligent scheduling, performance optimization, and lifecycle coordination.

**What it bundles:**
- Flexible recurring execution scheduling with multiple frequency options and time zone support
- Schedule monitoring with performance optimization and conflict resolution
- Automated execution coordination with intelligent retry logic and failure recovery
- Schedule modification and lifecycle management with version control
- Performance analysis with optimization recommendations and resource management

**API Functions Used:**
- `GET /cleanrooms/{cleanroomId}/schedules` - Schedule enumeration with detailed configuration
- `POST /cleanrooms/{cleanroomId}/schedules` - Schedule creation with validation and optimization
- `PUT /schedules/{scheduleId}` - Schedule modification with conflict detection
- `DELETE /schedules/{scheduleId}` - Schedule deletion with dependency checking
- `PUT /schedules/{scheduleId}/pause` - Schedule pause/resume with state management

**User input needed:**
- action: Schedule action (list, create, update, delete, pause, resume) (required)
- cleanroomId: Cleanroom name, Display ID (CR-XXXXXX), or UUID (required)
- questionId: Question ID for schedule operations (required for create/update)
- scheduleId: Schedule ID for modifications (required for update/delete/pause/resume)
- scheduleConfig: Schedule configuration with frequency and timing (optional)
- parameters: Runtime parameters for scheduled executions (optional)

**Built-in logic:**
- **Schedule Intelligence**: Flexible scheduling with conflict detection and optimization
- **Performance Optimization**: Schedule optimization based on historical execution performance
- **Failure Recovery**: Automated failure recovery with intelligent retry logic and escalation
- **Lifecycle Management**: Comprehensive schedule lifecycle with version control and audit trail
- **Resource Coordination**: Intelligent resource management with load balancing and optimization

**Example prompt for testing:** "List all scheduled runs for cleanroom CR-045487. I want to see which questions are set to run automatically and their schedules."

---

## üîÑ Complete Tool Summary

**Foundation Tools (8):** Authentication, discovery, connection management, health monitoring
**Clean Room Management (4):** Creation, configuration, health monitoring, lifecycle management  
**Data Connections (14):** Multi-cloud wizards, health monitoring, field configuration
**Partner Collaboration (4):** Invitations, permissions, onboarding, coordination
**Question Management (4):** Deployment, permissions, scheduling, validation
**Dataset Management (4):** Provisioning, configuration, permissions, transformations
**Results & Monitoring (4):** Execution, status checking, export, scheduling
**Advanced Features (3):** Templates, user management, security auditing

---

**Total Tools Documented: 45** ‚úÖ  
**Source: Live MCP Server Source Code Analysis** ‚úÖ  
**API Coverage: Comprehensive with 100+ endpoints mapped** ‚úÖ  
**Last Updated: January 17, 2025** ‚úÖ

*This documentation was extracted directly from the production MCP server source code at `/mcp-habu-runner/src/index.ts` and represents the complete technical implementation of all 45 tools.*
